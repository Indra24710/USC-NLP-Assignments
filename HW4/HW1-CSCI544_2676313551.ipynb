{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\indra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Pytorch_practice\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3457: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "org_df=pd.read_csv(\"./dataset.tsv\",sep='\\t',on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body star_rating\n",
       "0  so beautiful even tho clearly not high end ......           5\n",
       "1  Great product.. I got this set for my mother, ...           5\n",
       "2  Exactly as pictured and my daughter's friend l...           5\n",
       "3  Love it. Fits great. Super comfortable and nea...           5\n",
       "4  Got this as a Mother's Day gift for my Mom and...           5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_columns=['review_body','star_rating']\n",
    "df=org_df[required_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We select 20000 reviews randomly from each rating class.\n",
    "\n",
    "#### Selecting 50,000 reviews per class to account for possible loss of complete input text value in certain rows during the data cleaning process. Inputs are later reduced to 20,000 per class before the tf-idf vectorization step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1166407</th>\n",
       "      <td>I returned it for the broken clasp, but the br...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582207</th>\n",
       "      <td>The look of the item is great! The quality of ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069996</th>\n",
       "      <td>One of the lockets came off of the cylinder, i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481279</th>\n",
       "      <td>Not as pretty or feminine as I had hoped.  Kin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438448</th>\n",
       "      <td>My ear was too big for these and I have a pret...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_body star_rating\n",
       "1166407  I returned it for the broken clasp, but the br...           1\n",
       "1582207  The look of the item is great! The quality of ...         1.0\n",
       "1069996  One of the lockets came off of the cylinder, i...           1\n",
       "481279   Not as pretty or feminine as I had hoped.  Kin...           1\n",
       "438448   My ear was too big for these and I have a pret...           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "new_df=pd.DataFrame({\"review_body\":[],\"star_rating\":[]})\n",
    "for i in range(1,6):\n",
    "    new_df=pd.concat([new_df,df.loc[df['star_rating']==i].sample(50000)])\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I returned it for the broken clasp, but the braclet is TINY.  Can only imagine wearing it as one of many, many on my wrist at a time.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charcount_init=0\n",
    "charcount_final=0\n",
    "str(new_df['review_body'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "remove_html_tags='<.*?>';\n",
    "remove_urls='http\\S+';\n",
    "remove_non_alpha='[^A-Za-z ]'\n",
    "remove_extra_space=' +'\n",
    "processed={\"review_body\":[],\"star_rating\":[]}\n",
    "for i in range(len(new_df)):\n",
    "    s=str(new_df['review_body'].iloc[i])\n",
    "    c=new_df['star_rating'].iloc[i]\n",
    "    charcount_init+=len(s)\n",
    "    if s==\"\":\n",
    "        continue\n",
    "    s=re.sub(remove_html_tags,\"\",s)\n",
    "    s=re.sub(remove_urls,\"\",s)\n",
    "    s=re.sub(remove_non_alpha,\"\",s)\n",
    "    s=re.sub(remove_extra_space,\" \",s)\n",
    "    if s==\"\":\n",
    "        continue\n",
    "    processed[\"review_body\"].append(contractions.fix(s.lower()))\n",
    "    charcount_final+=len(processed[\"review_body\"][-1])\n",
    "    processed[\"star_rating\"].append(int(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i returned it for the broken clasp but the braclet is tiny can only imagine wearing it as one of many many on my wrist at a time'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "processed[\"review_body\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47033946 45171043\n"
     ]
    }
   ],
   "source": [
    "#Count before cleaning and after cleaning\n",
    "print(charcount_init,charcount_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with stop words: way too small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\indra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "without stop words: way small\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "pre_processcount=0\n",
    "\n",
    "print(\"with stop words:\",processed['review_body'][5001])\n",
    "for i in range(len(processed['review_body'])):\n",
    "    s=processed['review_body'][i]\n",
    "    pre_processcount+=len(s)\n",
    "    s=s.split(\" \")\n",
    "    s=[word for word in s if word not in stop_words]\n",
    "    s=\" \".join(s)\n",
    "    processed['review_body'][i]=s\n",
    "print()\n",
    "print(\"without stop words:\",processed['review_body'][5001])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before stemming:  way small\n",
      "after stemming:  way small\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "pre_stemmcount=0\n",
    "post_stemmcount=0\n",
    "print(\"before stemming: \",processed['review_body'][5001])\n",
    "for i in range(len(processed['review_body'])):\n",
    "    s=processed['review_body'][i]\n",
    "    pre_stemmcount+=len(s)\n",
    "    s=s.split(\" \")\n",
    "    s=[ps.stem(word) for word in s]\n",
    "    s=\" \".join(s)\n",
    "    post_stemmcount+=len(s)\n",
    "    processed[\"review_body\"][i]=s\n",
    "print(\"after stemming: \",processed['review_body'][5001])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without lemmatization: return broken clasp braclet tini imagin wear one mani mani wrist time\n",
      "Before processing and after processing count 45171043 16115424\n",
      "with lemmatization: return broken clasp braclet tini imagin wear one mani mani wrist time\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "post_processcount=0\n",
    "\n",
    "print(\"without lemmatization:\",processed['review_body'][0])\n",
    "\n",
    "count={1:0,2:0,3:0,4:0,5:0}\n",
    "final_processed_text={\"input\":[],\"target\":[]}\n",
    "for i in range(len(processed['review_body'])):\n",
    "    s=processed['review_body'][i]\n",
    "    c=processed['star_rating'][i]\n",
    "    if count[int(c)]>=20000:\n",
    "        continue\n",
    "    s=s.split(\" \")\n",
    "    s=[lemmatizer.lemmatize(word) for word in s]\n",
    "    if len(s)<13:\n",
    "        continue\n",
    "    s=\" \".join(s)\n",
    "    post_processcount+=len(s)\n",
    "    final_processed_text[\"input\"].append(s)\n",
    "    final_processed_text[\"target\"].append(int(c))\n",
    "    count[int(c)]+=1\n",
    "print(\"Before processing and after processing count\",pre_processcount,post_processcount)\n",
    "print(\"with lemmatization:\",processed['review_body'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 20000, 2: 20000, 3: 20000, 4: 20000, 5: 20000}\n"
     ]
    }
   ],
   "source": [
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "vector_rep=tfidf.fit_transform(final_processed_text['input'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrain:  (80000, 51898)\n",
      "ytrain:  80000\n",
      "Xtest:  (20000, 51898)\n",
      "ytest:  20000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest=train_test_split(vector_rep,final_processed_text['target'],shuffle=True,test_size=0.2,random_state=1)\n",
    "print(\"Xtrain: \",Xtrain.shape)\n",
    "print(\"ytrain: \",len(ytrain))\n",
    "print(\"Xtest: \",Xtest.shape)\n",
    "print(\"ytest: \",len(ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41605"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron=Perceptron()\n",
    "perceptron.fit(Xtrain,ytrain)\n",
    "perceptron.score(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4992"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm=LinearSVC()\n",
    "svm.fit(Xtrain,ytrain)\n",
    "svm.score(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg=LogisticRegression(max_iter=400)\n",
    "log_reg.fit(Xtrain,ytrain)\n",
    "log_reg.score(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4998"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb=MultinomialNB()\n",
    "nb.fit(Xtrain,ytrain)\n",
    "nb.score(Xtest,ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classification reports for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perceptron report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.52      0.52      4081\n",
      "           2       0.33      0.27      0.30      4029\n",
      "           3       0.31      0.33      0.32      3965\n",
      "           4       0.37      0.41      0.39      4015\n",
      "           5       0.55      0.55      0.55      3910\n",
      "\n",
      "    accuracy                           0.42     20000\n",
      "   macro avg       0.42      0.42      0.41     20000\n",
      "weighted avg       0.41      0.42      0.41     20000\n",
      "\n",
      "svm report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.65      0.61      4081\n",
      "           2       0.40      0.34      0.37      4029\n",
      "           3       0.40      0.35      0.37      3965\n",
      "           4       0.46      0.42      0.44      4015\n",
      "           5       0.61      0.74      0.67      3910\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.49      0.50      0.49     20000\n",
      "weighted avg       0.49      0.50      0.49     20000\n",
      "\n",
      "logistic regression report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.64      0.62      4081\n",
      "           2       0.42      0.38      0.40      4029\n",
      "           3       0.42      0.40      0.41      3965\n",
      "           4       0.49      0.46      0.48      4015\n",
      "           5       0.65      0.72      0.68      3910\n",
      "\n",
      "    accuracy                           0.52     20000\n",
      "   macro avg       0.51      0.52      0.52     20000\n",
      "weighted avg       0.51      0.52      0.52     20000\n",
      "\n",
      "naive bayes model report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.59      0.60      4081\n",
      "           2       0.40      0.38      0.39      4029\n",
      "           3       0.39      0.40      0.40      3965\n",
      "           4       0.46      0.45      0.46      4015\n",
      "           5       0.64      0.68      0.66      3910\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.50     20000\n",
      "weighted avg       0.50      0.50      0.50     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "perceptron_pred=perceptron.predict(Xtest)\n",
    "svmpred=svm.predict(Xtest)\n",
    "log_reg_pred=log_reg.predict(Xtest)\n",
    "nb_pred=nb.predict(Xtest)\n",
    "\n",
    "percept=classification_report(ytest,perceptron_pred)\n",
    "svm_rep=classification_report(ytest,svmpred)\n",
    "log_reg_rep=classification_report(ytest,log_reg_pred)\n",
    "nb_rep=classification_report(ytest,nb_pred)\n",
    "\n",
    "print(\"perceptron report:\")\n",
    "print(percept)\n",
    "print(\"svm report:\")\n",
    "print(svm_rep)\n",
    "print(\"logistic regression report:\")\n",
    "print(log_reg_rep)\n",
    "print(\"naive bayes model report:\")\n",
    "print(nb_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the required fields from each report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getreportvalues(rep):\n",
    "    rep=rep.split(\"\\n\")\n",
    "    rep=[i.split(\" \") for i in rep]\n",
    "    fin_rep=[]\n",
    "    for i in rep:\n",
    "        if i!=[]:\n",
    "            temp=[]\n",
    "            for j in i:\n",
    "                if j!='':\n",
    "                    temp.append(j)\n",
    "            if temp!=[]:\n",
    "                fin_rep.append(temp)\n",
    "    return fin_rep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52,0.52,0.52\n",
      "0.33,0.27,0.30\n",
      "0.31,0.33,0.32\n",
      "0.37,0.41,0.39\n",
      "0.55,0.55,0.55\n",
      "0.42,0.42,0.41\n"
     ]
    }
   ],
   "source": [
    "##perceptron report\n",
    "rep=getreportvalues(percept)\n",
    "for i in range(1,6):\n",
    "    s=\",\".join(rep[i][1:4])\n",
    "    print(s)\n",
    "print(\",\".join(rep[-2][2:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57,0.65,0.61\n",
      "0.40,0.34,0.37\n",
      "0.40,0.35,0.37\n",
      "0.46,0.42,0.44\n",
      "0.61,0.74,0.67\n",
      "0.49,0.50,0.49\n"
     ]
    }
   ],
   "source": [
    "##svm report\n",
    "rep=getreportvalues(svm_rep)\n",
    "for i in range(1,6):\n",
    "    s=\",\".join(rep[i][1:4])\n",
    "    print(s)\n",
    "print(\",\".join(rep[-2][2:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59,0.64,0.62\n",
      "0.42,0.38,0.40\n",
      "0.42,0.40,0.41\n",
      "0.49,0.46,0.48\n",
      "0.65,0.72,0.68\n",
      "0.51,0.52,0.52\n"
     ]
    }
   ],
   "source": [
    "##logistic regression report\n",
    "rep=getreportvalues(log_reg_rep)\n",
    "for i in range(1,6):\n",
    "    s=\",\".join(rep[i][1:4])\n",
    "    print(s)\n",
    "print(\",\".join(rep[-2][2:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60,0.59,0.60\n",
      "0.40,0.38,0.39\n",
      "0.39,0.40,0.40\n",
      "0.46,0.45,0.46\n",
      "0.64,0.68,0.66\n",
      "0.50,0.50,0.50\n"
     ]
    }
   ],
   "source": [
    "## naive bayes report\n",
    "rep=getreportvalues(nb_rep)\n",
    "for i in range(1,6):\n",
    "    s=\",\".join(rep[i][1:4])\n",
    "    print(s)\n",
    "print(\",\".join(rep[-2][2:5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
